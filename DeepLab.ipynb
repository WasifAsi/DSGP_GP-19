{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqaHJkmd/425CzgCQRIs/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WasifAsi/DSGP_GP-19/blob/deeplabv3%2B/DeepLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Imports**"
      ],
      "metadata": {
        "id": "TT33Z7EzF5GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create model directory in Google Drive\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/shoreline_models'\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.0005\n",
        "batch_size = 6  # decreased from 8\n",
        "num_epochs = 200\n",
        "image_size = 540  # Increased from 240"
      ],
      "metadata": {
        "id": "Ygqb7k9LF9tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loss Functions**"
      ],
      "metadata": {
        "id": "glPlNjd2GIQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.003, gamma=5.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Apply sigmoid\n",
        "        pred_prob = torch.sigmoid(pred)\n",
        "\n",
        "        # Calculate pt\n",
        "        pt = target * pred_prob + (1 - target) * (1 - pred_prob)\n",
        "\n",
        "        # Calculate focal weight\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = -self.alpha * focal_weight * torch.log(pt + 1e-12)\n",
        "\n",
        "        return loss.mean()\n",
        "\n",
        "# Combine with Dice Loss\n",
        "class CombinedFocalDiceLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.8, gamma=2.0, dice_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.focal = FocalLoss(alpha=alpha, gamma=gamma)\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        focal_loss = self.focal(pred, target)\n",
        "\n",
        "        pred_prob = torch.sigmoid(pred)\n",
        "        intersection = (pred_prob * target).sum()\n",
        "        dice_loss = 1 - (2. * intersection + 1) / (pred_prob.sum() + target.sum() + 1)\n",
        "\n",
        "        return focal_loss + self.dice_weight * dice_loss"
      ],
      "metadata": {
        "id": "na8fg8BgGMe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Components**"
      ],
      "metadata": {
        "id": "D9xeolzlGdyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ASPPConv(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels, dilation):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "class ASPPPooling(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.shape[-2:]\n",
        "        for mod in self:\n",
        "            x = mod(x)\n",
        "        return F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, atrous_rates, out_channels=256):\n",
        "        super().__init__()\n",
        "        modules = []\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()))\n",
        "\n",
        "        rates = tuple(atrous_rates)\n",
        "        for rate in rates:\n",
        "            modules.append(ASPPConv(in_channels, out_channels, rate))\n",
        "\n",
        "        modules.append(ASPPPooling(in_channels, out_channels))\n",
        "\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(len(self.convs) * out_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        for conv in self.convs:\n",
        "            res.append(conv(x))\n",
        "        res = torch.cat(res, dim=1)\n",
        "        return self.project(res)\n"
      ],
      "metadata": {
        "id": "CrXJdZ40GgeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Main Model**"
      ],
      "metadata": {
        "id": "fF8IqQ_bGpIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial conv layers with reduced stride\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # ResNet-like blocks with modified strides\n",
        "        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, 3, stride=1)\n",
        "\n",
        "        # ASPP\n",
        "        self.aspp = ASPP(512, [6, 12, 18])  # Reduced dilation rates\n",
        "\n",
        "        # Low-level features conversion\n",
        "        self.low_level_conv = nn.Sequential(\n",
        "            nn.Conv2d(64, 48, 1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Auxiliary decoder\n",
        "        self.aux_decoder = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(256, 1, 1)\n",
        "        )\n",
        "\n",
        "        # Main decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(304, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Conv2d(256, num_classes, 1)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_size = x.size()[-2:]\n",
        "\n",
        "        # Initial convolutions\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Backbone\n",
        "        low_level_feat = self.layer1(x)\n",
        "        x = self.layer2(low_level_feat)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Auxiliary output\n",
        "        aux_out = self.aux_decoder(x)\n",
        "        aux_out = F.interpolate(aux_out, size=input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        # ASPP\n",
        "        x = self.aspp(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = F.interpolate(x, size=low_level_feat.shape[2:], mode='bilinear', align_corners=False)\n",
        "        low_level_feat = self.low_level_conv(low_level_feat)\n",
        "        x = torch.cat([x, low_level_feat], dim=1)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        # Final upsampling\n",
        "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        if self.training:\n",
        "            return x, aux_out\n",
        "        return x"
      ],
      "metadata": {
        "id": "UQ0Pcz9PGq-N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}