{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMOet5dKFjE8Nzwjg9bt1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WasifAsi/DSGP_GP-19/blob/deeplabv3%2B/DeepLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Imports**"
      ],
      "metadata": {
        "id": "TT33Z7EzF5GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create model directory in Google Drive\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/shoreline_models'\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "# Set hyperparameters\n",
        "learning_rate = 0.0005\n",
        "batch_size = 6  # decreased from 8\n",
        "num_epochs = 200\n",
        "image_size = 540  # Increased from 240"
      ],
      "metadata": {
        "id": "Ygqb7k9LF9tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loss Functions**"
      ],
      "metadata": {
        "id": "glPlNjd2GIQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.003, gamma=5.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Apply sigmoid\n",
        "        pred_prob = torch.sigmoid(pred)\n",
        "\n",
        "        # Calculate pt\n",
        "        pt = target * pred_prob + (1 - target) * (1 - pred_prob)\n",
        "\n",
        "        # Calculate focal weight\n",
        "        focal_weight = (1 - pt) ** self.gamma\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = -self.alpha * focal_weight * torch.log(pt + 1e-12)\n",
        "\n",
        "        return loss.mean()\n",
        "\n",
        "# Combine with Dice Loss\n",
        "class CombinedFocalDiceLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.8, gamma=2.0, dice_weight=0.5):\n",
        "        super().__init__()\n",
        "        self.focal = FocalLoss(alpha=alpha, gamma=gamma)\n",
        "        self.dice_weight = dice_weight\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        focal_loss = self.focal(pred, target)\n",
        "\n",
        "        pred_prob = torch.sigmoid(pred)\n",
        "        intersection = (pred_prob * target).sum()\n",
        "        dice_loss = 1 - (2. * intersection + 1) / (pred_prob.sum() + target.sum() + 1)\n",
        "\n",
        "        return focal_loss + self.dice_weight * dice_loss"
      ],
      "metadata": {
        "id": "na8fg8BgGMe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Components**"
      ],
      "metadata": {
        "id": "D9xeolzlGdyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ASPPConv(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels, dilation):\n",
        "        super().__init__(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "class ASPPPooling(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.shape[-2:]\n",
        "        for mod in self:\n",
        "            x = mod(x)\n",
        "        return F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, atrous_rates, out_channels=256):\n",
        "        super().__init__()\n",
        "        modules = []\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()))\n",
        "\n",
        "        rates = tuple(atrous_rates)\n",
        "        for rate in rates:\n",
        "            modules.append(ASPPConv(in_channels, out_channels, rate))\n",
        "\n",
        "        modules.append(ASPPPooling(in_channels, out_channels))\n",
        "\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Conv2d(len(self.convs) * out_channels, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = []\n",
        "        for conv in self.convs:\n",
        "            res.append(conv(x))\n",
        "        res = torch.cat(res, dim=1)\n",
        "        return self.project(res)\n"
      ],
      "metadata": {
        "id": "CrXJdZ40GgeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Main Model**"
      ],
      "metadata": {
        "id": "fF8IqQ_bGpIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial conv layers with reduced stride\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # ResNet-like blocks with modified strides\n",
        "        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(256, 512, 3, stride=1)\n",
        "\n",
        "        # ASPP\n",
        "        self.aspp = ASPP(512, [6, 12, 18])  # Reduced dilation rates\n",
        "\n",
        "        # Low-level features conversion\n",
        "        self.low_level_conv = nn.Sequential(\n",
        "            nn.Conv2d(64, 48, 1, bias=False),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Auxiliary decoder\n",
        "        self.aux_decoder = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(256, 1, 1)\n",
        "        )\n",
        "\n",
        "        # Main decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(304, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(256, 256, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Conv2d(256, num_classes, 1)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(ResBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(ResBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_size = x.size()[-2:]\n",
        "\n",
        "        # Initial convolutions\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Backbone\n",
        "        low_level_feat = self.layer1(x)\n",
        "        x = self.layer2(low_level_feat)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Auxiliary output\n",
        "        aux_out = self.aux_decoder(x)\n",
        "        aux_out = F.interpolate(aux_out, size=input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        # ASPP\n",
        "        x = self.aspp(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = F.interpolate(x, size=low_level_feat.shape[2:], mode='bilinear', align_corners=False)\n",
        "        low_level_feat = self.low_level_conv(low_level_feat)\n",
        "        x = torch.cat([x, low_level_feat], dim=1)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        # Final upsampling\n",
        "        x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        if self.training:\n",
        "            return x, aux_out\n",
        "        return x"
      ],
      "metadata": {
        "id": "UQ0Pcz9PGq-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dataset and transform**"
      ],
      "metadata": {
        "id": "vDtmy3fkH-qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShorelineDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = sorted(os.listdir(image_dir))\n",
        "        self.masks = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
        "\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = (mask > 128).astype(np.uint8)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "6PagxN-iIB58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Early stopping**"
      ],
      "metadata": {
        "id": "4K1neUBhIETk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=35, min_delta=1e-4):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return self.early_stop"
      ],
      "metadata": {
        "id": "iEdKc6p0IG5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dataset Transform and Loader function**"
      ],
      "metadata": {
        "id": "COX_Hp4yIJaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessing_transform(image_size=540):\n",
        "    return A.Compose([\n",
        "        A.Resize(image_size, image_size),\n",
        "        A.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_training_transform(image_size=540):\n",
        "    return A.Compose([\n",
        "        A.Resize(image_size, image_size),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.ShiftScaleRotate(p=0.5),\n",
        "        A.OneOf([\n",
        "            A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
        "            A.GridDistortion(p=0.5),\n",
        "            A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=0.5),\n",
        "        ], p=0.3),\n",
        "        A.OneOf([\n",
        "            A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "            A.MedianBlur(blur_limit=3, p=0.5),\n",
        "            A.MotionBlur(blur_limit=3, p=0.5),\n",
        "        ], p=0.3),\n",
        "        A.OneOf([\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
        "            A.HueSaturationValue(p=0.5),\n",
        "        ], p=0.3),\n",
        "        A.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def prepare_dataloaders(train_image_dir, train_mask_dir,\n",
        "                     val_image_dir, val_mask_dir,\n",
        "                     test_image_dir, test_mask_dir,\n",
        "                     batch_size=8, image_size=256):\n",
        "    \"\"\"\n",
        "    Prepare dataloaders using the specified directory structure\n",
        "    \"\"\"\n",
        "    # Create datasets\n",
        "    train_dataset = ShorelineDataset(\n",
        "        train_image_dir,\n",
        "        train_mask_dir,\n",
        "        transform=get_training_transform(image_size)\n",
        "    )\n",
        "\n",
        "    val_dataset = ShorelineDataset(\n",
        "        val_image_dir,\n",
        "        val_mask_dir,\n",
        "        transform=get_preprocessing_transform(image_size)\n",
        "    )\n",
        "\n",
        "    test_dataset = ShorelineDataset(\n",
        "        test_image_dir,\n",
        "        test_mask_dir,\n",
        "        transform=get_preprocessing_transform(image_size)\n",
        "    )\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "Q1JQftABINKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training function**"
      ],
      "metadata": {
        "id": "aJvdOkmiIY9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, num_epochs=200, learning_rate=5e-4):\n",
        "    # Calculate class weights\n",
        "    # Initialize loss function and optimizer\n",
        "   # No class weight calculation needed\n",
        "    criterion = CombinedFocalDiceLoss(alpha=0.003, gamma=5.0, dice_weight=0.5)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "    early_stopping = EarlyStopping(patience=25, min_delta=1e-4)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    training_data = {\n",
        "        \"loss\": [],\n",
        "        \"epoch\": [],\n",
        "        \"lr\": [],\n",
        "        \"val_loss\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for images, masks in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            images = images.to(device)\n",
        "            masks = masks.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            main_outputs, aux_outputs = model(images)\n",
        "\n",
        "            # Calculate main and auxiliary losses\n",
        "            main_loss = criterion(main_outputs, masks.unsqueeze(1))\n",
        "            aux_loss = criterion(aux_outputs, masks.unsqueeze(1))\n",
        "            loss = main_loss + 0.4 * aux_loss\n",
        "\n",
        "            loss.backward()\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_loader:\n",
        "                images = images.to(device)\n",
        "                masks = masks.float().to(device)\n",
        "                outputs = model(images)\n",
        "                # During validation, model returns only main output\n",
        "                val_loss += criterion(outputs, masks.unsqueeze(1)).item()\n",
        "\n",
        "        epoch_loss = total_loss / len(train_loader)\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Training Loss: {epoch_loss:.4f}')\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, 'best_shoreline_deeplabv3.pt'))\n",
        "\n",
        "        # Early stopping check\n",
        "        if early_stopping(val_loss):\n",
        "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
        "            break\n",
        "\n",
        "        # Update training data\n",
        "        training_data[\"loss\"].append(epoch_loss)\n",
        "        training_data[\"epoch\"].append(epoch)\n",
        "        training_data[\"lr\"].append(optimizer.param_groups[0]['lr'])\n",
        "        training_data[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        # Save training history periodically\n",
        "        if epoch % 5 == 0:\n",
        "            with open(os.path.join(MODEL_SAVE_PATH, 'training_history_deeplabv3.pkl'), 'wb') as f:\n",
        "                pickle.dump(training_data, f)\n",
        "\n",
        "    # Save final model and training history\n",
        "    torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, 'final_shoreline_deeplabv3.pt'))\n",
        "    with open(os.path.join(MODEL_SAVE_PATH, 'final_training_history_deeplabv3.pkl'), 'wb') as f:\n",
        "        pickle.dump(training_data, f)\n",
        "\n",
        "    return model, training_data"
      ],
      "metadata": {
        "id": "shedPto8If3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Main function**"
      ],
      "metadata": {
        "id": "ncdztU4lIjVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Set paths\n",
        "    train_image_dir = '/content/drive/MyDrive/training_satellite'\n",
        "    train_mask_dir = '/content/drive/MyDrive/training_mask'\n",
        "    val_image_dir = '/content/drive/MyDrive/validation_satellite'\n",
        "    val_mask_dir = '/content/drive/MyDrive/validation_mask'\n",
        "    test_image_dir = '/content/drive/MyDrive/testing_satellite'\n",
        "    test_mask_dir = '/content/drive/MyDrive/testing_mask'\n",
        "\n",
        "    # Create model directory\n",
        "    MODEL_SAVE_PATH = '/content/drive/MyDrive/shoreline_models'\n",
        "    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "    # Prepare dataloaders\n",
        "    train_loader, val_loader, test_loader = prepare_dataloaders(\n",
        "        train_image_dir=train_image_dir,\n",
        "        train_mask_dir=train_mask_dir,\n",
        "        val_image_dir=val_image_dir,\n",
        "        val_mask_dir=val_mask_dir,\n",
        "        test_image_dir=test_image_dir,\n",
        "        test_mask_dir=test_mask_dir,\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = DeepLabV3Plus(num_classes=1).to(device)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    trained_model, training_history = train_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        device=device,\n",
        "        num_epochs=num_epochs,\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "gMAeYWCQIuCE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}